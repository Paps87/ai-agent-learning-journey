# ğŸ“š Phase 3 - Ask-the-Web Agent : Documentation ComplÃ¨te

## ğŸ¯ Objectif de la Phase 3

CrÃ©er un **agent IA capable de rechercher sur le web** et de gÃ©nÃ©rer des rÃ©ponses intelligentes avec citations, similaire Ã  Perplexity AI.

---

## âœ… Ce qui a Ã©tÃ© rÃ©alisÃ©

### 1. **Recherche Web Intelligente** ğŸ”

**Module :** `web_search.py`

**FonctionnalitÃ©s :**
- Recherche via DuckDuckGo (API gratuite)
- **Circuit Breaker Pattern** pour la rÃ©silience
- Retry automatique avec backoff exponentiel
- Validation et nettoyage des rÃ©sultats
- Support multi-requÃªtes

**Points clÃ©s :**
```python
# Circuit Breaker : 3 Ã©tats (CLOSED, OPEN, HALF_OPEN)
# Ã‰vite de surcharger l'API en cas d'erreurs rÃ©pÃ©tÃ©es
# Retry : 3 tentatives max avec dÃ©lai exponentiel
```

**Test validÃ© :** âœ… 5 rÃ©sultats pour "OpenAI GPT" en 1-2s

---

### 2. **Parsing HTML et Chunking** ğŸ“„

**Module :** `html_parser.py`

**FonctionnalitÃ©s :**
- Extraction du contenu principal (BeautifulSoup)
- Suppression des Ã©lÃ©ments indÃ©sirables (ads, nav, footer)
- **TextChunker** : dÃ©coupage intelligent avec chevauchement
- PrÃ©servation de la structure logique (titres, paragraphes)

**Points clÃ©s :**
```python
# Chunking : 500 mots par chunk, 50 mots de chevauchement
# PrÃ©serve le contexte entre les chunks
# Fallback si parsing Ã©choue (sites protÃ©gÃ©s)
```

**Limitation :** Certains sites bloquent le scraping (Wikipedia, OpenAI)

---

### 3. **Pipeline RAG Ã‰tendu** ğŸ§ 

**Module :** `extended_rag_pipeline.py`

**FonctionnalitÃ©s :**
- **Fusion Local + Web** : Combine documents locaux (Phase 2) et web
- **MÃ©moire conversationnelle** : Historique des 10 derniÃ¨res questions
- **Cache de recherches** : Ã‰vite les recherches redondantes (24h TTL)
- **Scoring de pertinence** : Classe les rÃ©sultats par score
- **Diversification des sources** : Ã‰vite les doublons

**Points clÃ©s :**
```python
# Mode web-only : Fonctionne sans Qdrant (Phase 2 optionnelle)
# Indexation temporaire : Chunks web indexÃ©s pour 24h
# Fusion intelligente : Combine local (si dispo) + web
```

**Correction importante :** Attribut `local_available` ajoutÃ© pour gÃ©rer l'absence de Qdrant

---

### 4. **Orchestrateur d'Agent** ğŸ¤–

**Module :** `agent_orchestrator.py`

**FonctionnalitÃ©s :**
- **Analyse de complexitÃ©** : Ã‰value si question simple ou complexe
- **DÃ©composition en sous-questions** : Pour questions complexes
- **3 stratÃ©gies de recherche** :
  - **Single** : Question simple
  - **Parallel** : Plusieurs sous-questions en parallÃ¨le
  - **Sequential** : Sous-questions dÃ©pendantes
- **SynthÃ¨se multi-sources** : AgrÃ¨ge les rÃ©ponses

**Points clÃ©s :**
```python
# SearchPlanner : Analyse la question et choisit la stratÃ©gie
# Max depth : 3 niveaux de dÃ©composition
# SynthÃ¨se finale : Combine toutes les rÃ©ponses
```

**Correction importante :** Attribut `available` ajoutÃ© pour vÃ©rifier les composants

---

### 5. **IntÃ©gration LM Studio** ğŸ¨

**Module :** `lmstudio_client.py` (crÃ©Ã© durant cette phase)

**FonctionnalitÃ©s :**
- Client OpenAI-compatible pour LM Studio
- **GÃ©nÃ©ration avec contexte et sources**
- **Citations automatiques** [1], [2], [3]
- Timeout configurable (120s)
- Fallback si LM Studio offline

**Points clÃ©s :**
```python
# ModÃ¨le : gad-gpt-5-chat-llama-3.1-8b-instruct-i1
# Temperature : 0.3 (prÃ©cision)
# Max tokens : 1000 (rÃ©ponses rapides)
# Timeout : 120s (augmentÃ© pour Ã©viter timeouts)
```

**Optimisations appliquÃ©es :**
- Timeout augmentÃ© : 60s â†’ 120s
- Max tokens rÃ©duit : 2000 â†’ 1000 (rÃ©ponses plus rapides)

---

### 6. **Interface Utilisateur** ğŸ–¥ï¸

**Solution finale :** **Streamlit** (`app/main.py`)

**Pourquoi Streamlit ?**
- âœ… Pas de problÃ¨mes CORS
- âœ… Interface dÃ©jÃ  prÃªte
- âœ… Une seule commande pour lancer
- âœ… Rechargement automatique

**Tentatives abandonnÃ©es :**
- âŒ Backend FastAPI + Frontend HTML/JS : ProblÃ¨mes CORS insurmontables
- âŒ Servir frontend depuis backend : ProblÃ¨mes de cache navigateur

**FonctionnalitÃ©s de l'interface :**
- Recherche web en temps rÃ©el
- Affichage des rÃ©ponses avec citations
- Sources dÃ©taillÃ©es (titre, URL, type)
- Statistiques (temps, stratÃ©gie, nombre de sources)
- ParamÃ¨tres configurables (mode recherche, profondeur)

---

## ğŸ”§ Corrections et Optimisations

### ProblÃ¨mes RÃ©solus

1. **Qdrant non disponible**
   - **ProblÃ¨me :** Backend crashait si Qdrant non lancÃ©
   - **Solution :** Mode web-only avec flag `PHASE2_AVAILABLE`
   - **Impact :** Fonctionne sans Phase 2

2. **Timeout LM Studio**
   - **ProblÃ¨me :** GÃ©nÃ©ration prenait >60s, timeout
   - **Solution :** Timeout 120s + max_tokens 1000
   - **Impact :** RÃ©ponses en 15-50s au lieu de timeout

3. **Attributs manquants**
   - **ProblÃ¨me :** `local_available` et `available` non dÃ©finis
   - **Solution :** Initialisation dans `__init__`
   - **Impact :** Pas d'AttributeError

4. **MÃ©triques Streamlit**
   - **ProblÃ¨me :** Affichage littÃ©ral ".2f" au lieu de valeurs
   - **Solution :** Formatage correct avec f-strings
   - **Impact :** Affichage propre des statistiques

5. **CORS Frontend/Backend**
   - **ProblÃ¨me :** Navigateur bloquait requÃªtes cross-origin
   - **Solution :** Abandon FastAPI, utilisation Streamlit
   - **Impact :** Plus de problÃ¨mes CORS

---

## ğŸ“Š Architecture Finale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Interface Streamlit (port 8501)  â”‚
â”‚   - Questions / RÃ©ponses            â”‚
â”‚   - Sources et citations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Orchestrator                â”‚
â”‚   - Analyse complexitÃ©              â”‚
â”‚   - DÃ©composition questions         â”‚
â”‚   - Choix stratÃ©gie                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Web Search â”‚    â”‚ Extended RAG    â”‚
â”‚ (DuckDuckGoâ”‚    â”‚ Pipeline        â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTML Parserâ”‚    â”‚ LM Studio       â”‚
â”‚ + Chunking â”‚    â”‚ (GPT 8B)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Utilisation

### Lancement Simple

```bash
cd "/home/paps/Projet ai/phase3"
./run_streamlit.sh
```

**Ou :**
```bash
cd "/home/paps/Projet ai"
source venv/bin/activate
streamlit run phase3/app/main.py
```

### PrÃ©requis

1. **LM Studio lancÃ©** sur port 1234
2. **ModÃ¨le chargÃ©** (GPT 8B recommandÃ©)
3. **Venv activÃ©** avec dÃ©pendances installÃ©es

### Workflow Utilisateur

1. Ouvrir http://localhost:8501
2. Taper question : "Quel est le prix du Bitcoin?"
3. Cliquer "Rechercher"
4. Attendre 15-60 secondes
5. Voir rÃ©ponse avec citations [1], [2], [3]
6. Consulter sources en bas

---

## ğŸ“ˆ Performance

**Temps de traitement typique :**
- Recherche web : 1-3s
- Parsing HTML : 0.5-1s
- GÃ©nÃ©ration LLM : 10-40s
- **Total : 15-50s**

**Optimisations :**
- Circuit Breaker : Ã‰vite surcharge API
- Cache 24h : Ã‰vite recherches redondantes
- Chunking intelligent : PrÃ©serve contexte
- Max tokens rÃ©duit : RÃ©ponses plus rapides

---

## ğŸ“ Structure des Fichiers

```
phase3/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ web_search.py              # âœ… Recherche DuckDuckGo
â”‚   â”œâ”€â”€ html_parser.py             # âœ… Parsing + Chunking
â”‚   â”œâ”€â”€ extended_rag_pipeline.py   # âœ… RAG Local+Web
â”‚   â”œâ”€â”€ agent_orchestrator.py      # âœ… Orchestration
â”‚   â””â”€â”€ lmstudio_client.py         # ğŸ†• Client LM Studio
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py                    # âœ… Interface Streamlit
â”‚
â”œâ”€â”€ backend/                       # âŒ Non utilisÃ© (CORS)
â”œâ”€â”€ frontend/                      # âŒ Non utilisÃ© (CORS)
â”‚
â”œâ”€â”€ run_streamlit.sh               # ğŸ†• Script lancement
â”œâ”€â”€ PHASE3_COMPLETE.md             # ğŸ†• Cette doc
â””â”€â”€ README.md                      # Doc originale
```

---

## ğŸ“ Apprentissages ClÃ©s

### Techniques MaÃ®trisÃ©es

1. **Web Scraping** avec BeautifulSoup
2. **Circuit Breaker Pattern** pour rÃ©silience
3. **RAG hybride** (local + web)
4. **Chunking intelligent** avec chevauchement
5. **Orchestration multi-stratÃ©gies**
6. **IntÃ©gration LLM local** (LM Studio)
7. **Gestion d'erreurs robuste** (retry, fallback)

### DÃ©fis SurmontÃ©s

1. **CORS** : RÃ©solu en utilisant Streamlit
2. **Timeout LLM** : RÃ©solu en augmentant timeout + rÃ©duisant tokens
3. **DÃ©pendances optionnelles** : Mode web-only sans Qdrant
4. **Sites protÃ©gÃ©s** : Fallback gracieux si parsing Ã©choue

### Bonnes Pratiques

1. **Factory Pattern** : `get_web_search_engine()`, `get_lm_studio_client()`
2. **Logging complet** : Tous les modules loggent leurs actions
3. **Gestion d'erreurs** : Try/except avec messages clairs
4. **Configuration centralisÃ©e** : Timeouts, max_results, etc.
5. **Tests unitaires** : Chaque module testable indÃ©pendamment

---

## ğŸ” Tests de Validation

### Test 1 : Recherche Web
```bash
cd phase3/src
python web_search.py
```
**RÃ©sultat :** âœ… 3 rÃ©sultats pour "prix bitcoin"

### Test 2 : LM Studio
```bash
cd phase3/src
python lmstudio_client.py
```
**RÃ©sultat :** âœ… GÃ©nÃ©ration avec citations [1], [2]

### Test 3 : Workflow Complet
```bash
cd phase3
python test_validation.py
```
**RÃ©sultat :** âœ… Pipeline OK (local_available=False)

### Test 4 : Interface Streamlit
```bash
streamlit run phase3/app/main.py
```
**RÃ©sultat :** âœ… RÃ©ponse "pancakes" en 28.37s avec sources

---

## ğŸ’¡ Recommandations pour Production

### AmÃ©liorations Possibles

1. **Streaming des rÃ©ponses** : SSE pour affichage progressif
2. **Cache persistant** : Redis au lieu de mÃ©moire
3. **API officielle** : Remplacer DuckDuckGo par API payante
4. **ModÃ¨le plus rapide** : 3B ou 7B au lieu de 8B
5. **Historique permanent** : Base de donnÃ©es pour conversations
6. **Export PDF** : Sauvegarder rÃ©ponses avec sources

### SÃ©curitÃ©

1. **Rate limiting** : Limiter requÃªtes par utilisateur
2. **Validation input** : Sanitize questions utilisateur
3. **HTTPS** : En production
4. **API keys** : Pour services externes

---

## ğŸ“Š Statistiques du Projet

**Lignes de code :**
- `web_search.py` : ~300 lignes
- `html_parser.py` : ~520 lignes
- `extended_rag_pipeline.py` : ~590 lignes
- `agent_orchestrator.py` : ~390 lignes
- `lmstudio_client.py` : ~260 lignes
- `main.py` (Streamlit) : ~320 lignes
- **Total : ~2380 lignes**

**DÃ©pendances ajoutÃ©es :**
- `ddgs` (DuckDuckGo)
- `beautifulsoup4` (Parsing HTML)
- `streamlit` (Interface)
- `requests` (HTTP)

**Temps de dÃ©veloppement :** ~8-10 heures (avec dÃ©bogage)

---

## ğŸ‰ Conclusion Phase 3

**Objectif atteint :** âœ… Agent web-aware fonctionnel

**Points forts :**
- âœ… Recherche web en temps rÃ©el
- âœ… GÃ©nÃ©ration LLM locale (gratuit, privÃ©)
- âœ… Citations automatiques [1], [2], [3]
- âœ… Interface simple et efficace
- âœ… Architecture modulaire et extensible

**Limitations :**
- âš ï¸ Parsing Ã©choue sur sites protÃ©gÃ©s
- âš ï¸ GÃ©nÃ©ration lente (15-50s)
- âš ï¸ Pas de streaming
- âš ï¸ Cache en mÃ©moire (non persistant)

**PrÃªt pour Phase 4 !** ğŸš€

---

**Fichiers importants :**
- [run_streamlit.sh](file:///home/paps/Projet%20ai/phase3/run_streamlit.sh) - Lancement
- [main.py](file:///home/paps/Projet%20ai/phase3/app/main.py) - Interface
- [lmstudio_client.py](file:///home/paps/Projet%20ai/phase3/src/lmstudio_client.py) - LLM
- [agent_orchestrator.py](file:///home/paps/Projet%20ai/phase3/src/agent_orchestrator.py) - Orchestration
