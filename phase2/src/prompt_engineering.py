"""
Techniques avanc√©es de Prompt Engineering pour RAG - Phase 2
Am√©lioration des prompts pour des r√©ponses plus pr√©cises et contextuelles
"""

from typing import List, Dict, Any, Optional
import logging
from enum import Enum

logger = logging.getLogger(__name__)

class PromptStyle(Enum):
    """Styles de prompts disponibles"""
    CONCISE = "concise"  # R√©ponses courtes et directes
    DETAILED = "detailed"  # R√©ponses d√©taill√©es avec explications
    TECHNICAL = "technical"  # Langage technique pour experts
    FRIENDLY = "friendly"  # Ton amical et accessible
    FORMAL = "formal"  # Langage formel professionnel

class RoleType(Enum):
    """Types de r√¥les pour le prompt engineering"""
    IT_SUPPORT = "it_support"
    HR_ASSISTANT = "hr_assistant"
    GENERAL_ASSISTANT = "general_assistant"
    TECHNICAL_EXPERT = "technical_expert"

class PromptEngineer:
    """
    Gestionnaire de prompt engineering avanc√©
    Techniques: role-playing, chain-of-thought, few-shot learning, etc.
    """

    def __init__(self):
        self.role_templates = self._initialize_role_templates()
        self.style_templates = self._initialize_style_templates()
        logger.info("PromptEngineer initialis√©")

    def _initialize_role_templates(self) -> Dict[RoleType, str]:
        """Initialise les templates de r√¥les"""
        return {
            RoleType.IT_SUPPORT: """
Tu es un expert en support informatique chez TechCorp. Ton r√¥le est d'aider les employ√©s avec:
- Probl√®mes techniques et configurations
- Acc√®s aux syst√®mes et authentification
- Mat√©riel informatique et logiciels
- S√©curit√© et bonnes pratiques

Ton expertise: r√©seaux, VPN, emails, imprimantes, mots de passe, Active Directory.
""",

            RoleType.HR_ASSISTANT: """
Tu es un assistant RH chez TechCorp. Ton r√¥le est d'aider avec:
- Demandes de cong√©s et absences
- Processus d'√©valuation et d√©veloppement
- Avantages sociaux et r√©mun√©ration
- Politiques d'entreprise et proc√©dures

Ton expertise: portail RH, cong√©s pay√©s, √©valuations, formations.
""",

            RoleType.TECHNICAL_EXPERT: """
Tu es un expert technique senior chez TechCorp. Ton public est technique:
- D√©veloppeurs, DevOps, ing√©nieurs syst√®me
- Langage technique pr√©cis et d√©taill√©
- Solutions complexes et architectures
- Bonnes pratiques et optimisations
""",

            RoleType.GENERAL_ASSISTANT: """
Tu es un assistant g√©n√©ral chez TechCorp. Ton r√¥le est d'aider avec:
- Questions g√©n√©rales sur l'entreprise
- Orientation vers les bons services
- Informations de base et proc√©dures
- Support polyvalent et bienveillant
"""
        }

    def _initialize_style_templates(self) -> Dict[PromptStyle, str]:
        """Initialise les templates de styles"""
        return {
            PromptStyle.CONCISE: "R√©ponds de mani√®re concise et directe. Maximum 2-3 phrases.",
            PromptStyle.DETAILED: """
Fournis une r√©ponse d√©taill√©e avec:
- Explications √©tape par √©tape
- Contextes et raisons
- Exemples concrets si pertinent
- Alternatives possibles
""",
            PromptStyle.TECHNICAL: """
Utilise un langage technique pr√©cis:
- Terminologie sp√©cifique au domaine
- D√©tails techniques approfondis
- R√©f√©rences aux syst√®mes internes
- Codes d'erreur et solutions techniques
""",
            PromptStyle.FRIENDLY: """
Adopte un ton amical et accessible:
- Langage simple et clair
- Empathie et encouragement
- Emojis occasionnels si appropri√© üòä
- Phrases courtes et positives
""",
            PromptStyle.FORMAL: """
Utilise un langage formel professionnel:
- Structure officielle et polie
- Termes pr√©cis et complets
- Formulations diplomatiques
- Respect des protocoles d'entreprise
"""
        }

    def detect_role_from_query(self, query: str) -> RoleType:
        """
        D√©tecte automatiquement le r√¥le appropri√© bas√© sur la requ√™te

        Args:
            query: Question de l'utilisateur

        Returns:
            RoleType appropri√©
        """
        query_lower = query.lower()
        
        # D√©tection bas√©e sur les mots-cl√©s
        it_keywords = ['vpn', 'mot de passe', 'email', 'imprimante', 'r√©seau', 'configurer', 'technique']
        hr_keywords = ['cong√©s', 'rh', '√©valuation', 'formation', 'salaire', 'avantages', 'absences']
        technical_keywords = ['api', 'code', 'd√©ploiement', 'git', 'docker', 'kubernetes', 'database']
        
        if any(keyword in query_lower for keyword in it_keywords):
            return RoleType.IT_SUPPORT
        elif any(keyword in query_lower for keyword in hr_keywords):
            return RoleType.HR_ASSISTANT
        elif any(keyword in query_lower for keyword in technical_keywords):
            return RoleType.TECHNICAL_EXPERT
        else:
            return RoleType.GENERAL_ASSISTANT

    def detect_style_from_query(self, query: str) -> PromptStyle:
        """
        D√©tecte automatiquement le style appropri√©

        Args:
            query: Question de l'utilisateur

        Returns:
            PromptStyle appropri√©
        """
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['d√©taill√©', 'explication', 'comment', 'pourquoi']):
            return PromptStyle.DETAILED
        elif any(word in query_lower for word in ['technique', 'expert', 'avanc√©', 'config']):
            return PromptStyle.TECHNICAL
        elif any(word in query_lower for word in ['simple', 'rapide', 'court', 'r√©sum√©']):
            return PromptStyle.CONCISE
        elif any(word in query_lower for word in ['urgence', 'important', 'officiel']):
            return PromptStyle.FORMAL
        else:
            return PromptStyle.FRIENDLY

    def build_enhanced_prompt(self, query: str, context: str, 
                           role: Optional[RoleType] = None,
                           style: Optional[PromptStyle] = None) -> str:
        """
        Construit un prompt avanc√© avec engineering

        Args:
            query: Question de l'utilisateur
            context: Contexte RAG
            role: R√¥le sp√©cifique (optionnel, auto-d√©tect√© sinon)
            style: Style sp√©cifique (optionnel, auto-d√©tect√© sinon)

        Returns:
            Prompt optimis√©
        """
        # Auto-d√©tection si non sp√©cifi√©
        detected_role = role or self.detect_role_from_query(query)
        detected_style = style or self.detect_style_from_query(query)
        
        # R√©cup√©rer les templates
        role_template = self.role_templates[detected_role]
        style_template = self.style_templates[detected_style]
        
        prompt = f"""
# R√îLE ET CONTEXTE
{role_template}

# STYLE DE R√âPONSE
{style_template}

# CONTRAINTES IMPORTANTES
- Utilise EXCLUSIVEMENT le contexte fourni pour r√©pondre
- Si l'information n'est pas dans le contexte, dis clairement que tu ne sais pas
- Ne invente jamais d'information
- Cite tes sources quand c'est pertinent
- Sois pr√©cis et factuel

# CONTEXTE DOCUMENTAIRE
{context}

# QUESTION UTILISATEUR
{query}

# R√âPONSE (en fran√ßais):
"""
        logger.info(f"Prompt construit - R√¥le: {detected_role.value}, Style: {detected_style.value}")
        return prompt.strip()

    def add_chain_of_thought(self, prompt: str) -> str:
        """
        Ajoute un raisonnement √©tape par √©tape au prompt

        Args:
            prompt: Prompt original

        Returns:
            Prompt avec chain-of-thought
        """
        cot_addition = """

# PROCESSUS DE RAISONNEMENT
Avant de r√©pondre, r√©fl√©chis √©tape par √©tape:
1. Analyse la question et identifie le besoin principal
2. Examine le contexte pour trouver les informations pertinentes  
3. V√©rifie la coh√©rence et la compl√©tude des informations
4. Structure ta r√©ponse de mani√®re logique
5. Valide que la r√©ponse est bas√©e uniquement sur le contexte

Maintenant, fournis ta r√©ponse:
"""
        return prompt + cot_addition

    def add_few_shot_examples(self, prompt: str, examples: List[Dict[str, str]]) -> str:
        """
        Ajoute des exemples few-shot au prompt

        Args:
            prompt: Prompt original
            examples: Liste d'exemples {question: ..., r√©ponse: ...}

        Returns:
            Prompt avec exemples
        """
        examples_section = "\n\n# EXEMPLES DE R√âPONSES (√† suivre comme mod√®le):\n"
        
        for i, example in enumerate(examples, 1):
            examples_section += f"""
Exemple {i}:
Question: {example['question']}
R√©ponse: {example['answer']}
"""
        
        return prompt + examples_section

    def add_validation_check(self, prompt: str) -> str:
        """
        Ajoute une v√©rification de validation de r√©ponse

        Args:
            prompt: Prompt original

        Returns:
            Prompt avec validation
        """
        validation_add = """

# VALIDATION FINALE
Avant de soumettre ta r√©ponse, v√©rifie:
‚úÖ La r√©ponse est bas√©e √† 100% sur le contexte fourni
‚úÖ Aucune information n'est invent√©e ou extrapol√©e  
‚úÖ Le ton et le style correspondent au r√¥le
‚úÖ La r√©ponse est compl√®te mais concise
‚úÖ Les sources sont cit√©es si n√©cessaire

R√©ponse finale:
"""
        return prompt + validation_add

# Instance globale
prompt_engineer = PromptEngineer()

def get_prompt_engineer() -> PromptEngineer:
    """Factory function pour l'instance globale"""
    return prompt_engineer

# Tests unitaires
if __name__ == "__main__":
    print("=== Test Prompt Engineering ===")
    
    try:
        engineer = PromptEngineer()
        
        # Test questions vari√©es
        test_queries = [
            "Comment configurer le VPN ?",
            "Je veux comprendre le processus d'√©valuation annuelle en d√©tail",
            "Probl√®me technique urgent avec mon email",
            "Simple rappel sur les cong√©s"
        ]
        
        context = "[Document 1]\nConfiguration VPN: vpn.entreprise.com\n[Document 2]\nCong√©s: portail RH\n[Document 3]\n√âvaluation: d√©cembre"
        
        for query in test_queries:
            print(f"\nüîç Query: {query}")
            
            # Auto-d√©tection
            role = engineer.detect_role_from_query(query)
            style = engineer.detect_style_from_query(query)
            
            print(f"ü§ñ R√¥le d√©tect√©: {role.value}")
            print(f"üé® Style d√©tect√©: {style.value}")
            
            # Construction prompt
            prompt = engineer.build_enhanced_prompt(query, context)
            print(f"üìù Prompt length: {len(prompt)} caract√®res")
            print(f"üìã Preview: {prompt[:200]}...")
        
        print("\n‚úÖ Tests Prompt Engineering r√©ussis !")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()