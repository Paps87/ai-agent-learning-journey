# ğŸš€ Flux d'ExÃ©cution - LLM Playground

## SchÃ©ma ASCII SimplifiÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UTILISATEUR   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COLLECTE       â”‚â”€â”€â”€â”€â–¶â”‚  TOKENISATION   â”‚â”€â”€â”€â”€â–¶â”‚  ENTRAÃNEMENT   â”‚
â”‚  download_data  â”‚     â”‚  preprocess     â”‚     â”‚  training       â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚ â€¢ Wikipedia API â”‚     â”‚ â€¢ SentencePiece â”‚     â”‚ â€¢ PyTorch       â”‚
â”‚ â€¢ Nettoyage     â”‚     â”‚ â€¢ BPE Training  â”‚     â”‚ â€¢ Next-Token    â”‚
â”‚ â€¢ Sauvegarde    â”‚     â”‚ â€¢ Tokenize      â”‚     â”‚ â€¢ Optimization  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚                       â”‚
          â–¼                       â–¼                       â–¼
    data/raw/               data/processed/            models/
wikipedia_corpus.txt     tokenized_corpus.txt      gpt_model.pth
                                                            â”‚
                                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INFERENCE      â”‚â—€â”€â”€â”€â”€â”‚  GÃ‰NÃ‰RATION     â”‚â—€â”€â”€â”€â”€â”‚  INTERFACE      â”‚
â”‚  GPTModel       â”‚     â”‚  Sampling       â”‚     â”‚  Streamlit      â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚ â€¢ Forward pass  â”‚     â”‚ â€¢ Greedy        â”‚     â”‚ â€¢ Chat UI       â”‚
â”‚ â€¢ Causal mask   â”‚     â”‚ â€¢ Top-k         â”‚     â”‚ â€¢ ParamÃ¨tres    â”‚
â”‚ â€¢ Logits        â”‚     â”‚ â€¢ Top-p         â”‚     â”‚ â€¢ Historique    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚                       â”‚
          â–¼                       â–¼                       â–¼
    TOKENS IDS              TEXTE GÃ‰NÃ‰RÃ‰            UTILISATEUR
    [1523, 4871, ...]     "The AI model..."       RÃ©ponse finale
```

## Pipeline Ã‰tape par Ã‰tape

### 1. **PHASE DE DONNÃ‰ES** ğŸ“Š
```
Internet â†’ Wikipedia API â†’ DataCollector â†’ Nettoyage â†’ Fichiers texte
```

**Fichiers gÃ©nÃ©rÃ©s :**
- `data/raw/wikipedia_corpus.txt` (articles concatÃ©nÃ©s)

### 2. **PHASE DE TOKENISATION** ğŸ”¤
```
Texte brut â†’ SentencePiece â†’ BPE Training â†’ Tokenization â†’ IDs numÃ©riques
```

**Fichiers gÃ©nÃ©rÃ©s :**
- `models/tokenizer.model` (modÃ¨le entraÃ®nÃ©)
- `models/tokenizer.vocab` (vocabulaire)
- `data/processed/tokenized_corpus.txt` (sÃ©quence d'IDs)

### 3. **PHASE D'ENTRAÃNEMENT** ğŸ§ 
```
Tokens IDs â†’ TextDataset â†’ DataLoader â†’ GPTModel â†’ Loss â†’ Optimization
```

**Fichiers gÃ©nÃ©rÃ©s :**
- `models/gpt_model.pth` (poids du modÃ¨le)
- Checkpoints intermÃ©diaires (optionnel)

### 4. **PHASE D'INFERENCE** ğŸ¯
```
Prompt â†’ Tokenizer.encode() â†’ GPTModel.generate() â†’ Tokenizer.decode() â†’ RÃ©ponse
```

**Composants utilisÃ©s :**
- ModÃ¨le chargÃ© en mÃ©moire
- Tokenizer pour conversion
- StratÃ©gies de sampling

### 5. **PHASE INTERFACE** ğŸ¨
```
Utilisateur â†’ Streamlit UI â†’ ParamÃ¨tres â†’ GÃ©nÃ©ration â†’ Affichage â†’ Historique
```

**Composants UI :**
- Zone de chat
- Sliders (temperature, top-k, etc.)
- Boutons de contrÃ´le
- Historique des messages

## Ã‰tats du SystÃ¨me

### Ã‰tat 0: Initial
```
ğŸ“ data/raw/          : Vide
ğŸ“ data/processed/    : Vide
ğŸ“ models/           : Vide
ğŸš« Interface         : Non disponible
```

### Ã‰tat 1: AprÃ¨s Collecte
```
ğŸ“ data/raw/          : âœ… wikipedia_corpus.txt
ğŸ“ data/processed/    : Vide
ğŸ“ models/           : âœ… tokenizer.model/.vocab
ğŸš« Interface         : Non disponible
```

### Ã‰tat 2: AprÃ¨s Tokenisation
```
ğŸ“ data/raw/          : âœ… wikipedia_corpus.txt
ğŸ“ data/processed/    : âœ… tokenized_corpus.txt
ğŸ“ models/           : âœ… tokenizer.model/.vocab
ğŸš« Interface         : Non disponible
```

### Ã‰tat 3: AprÃ¨s EntraÃ®nement
```
ğŸ“ data/raw/          : âœ… wikipedia_corpus.txt
ğŸ“ data/processed/    : âœ… tokenized_corpus.txt
ğŸ“ models/           : âœ… tokenizer.model/.vocab + gpt_model.pth
ğŸŸ¢ Interface         : Disponible !
```

## Flux de DonnÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STRING    â”‚â”€â”€â”€â–¶â”‚   TOKENS    â”‚â”€â”€â”€â–¶â”‚   TENSORS   â”‚â”€â”€â”€â–¶â”‚  LOGITS     â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â”‚ "Hello AI"  â”‚    â”‚ [1, 452, 89]â”‚    â”‚ tensor[...] â”‚    â”‚ tensor[...] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–²                    â–²                    â–²                    â–²
      â”‚                    â”‚                    â”‚                    â”‚
   DÃ©code               Encode              Forward            Sample
   (Tokenizer)          (Tokenizer)        (GPTModel)       (generate)
```

## Gestion d'Erreurs

### Points de ContrÃ´le
- âœ… Fichier de donnÃ©es existe ?
- âœ… Tokenizer entraÃ®nÃ© ?
- âœ… ModÃ¨le existe ?
- âœ… Interface peut charger le modÃ¨le ?

### RÃ©cupÃ©ration
- Si donnÃ©es manquent â†’ Relancer collecte
- Si tokenizer cassÃ© â†’ RÃ©-entraÃ®ner
- Si modÃ¨le corrompu â†’ Recharger depuis checkpoint
- Si interface plante â†’ VÃ©rifier chemins des fichiers

---

*Ce schÃ©ma montre le flux complet de donnÃ©es et d'exÃ©cution Ã  travers toutes les phases du projet.*