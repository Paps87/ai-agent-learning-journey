# ğŸ—ï¸ Architecture UML - LLM Playground Phase 1

## Diagramme de Classes UML

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LLM Playground                           â”‚
â”‚                        Phase 1                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Scripts d'ExÃ©cution                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  download_data.py     preprocess.py      training.py           â”‚
â”‚  â”‚                    â”‚                   â”‚                     â”‚
â”‚  â””â”€â”€ DataCollector    â””â”€â”€ Tokenizer       â””â”€â”€ TextDataset       â”‚
â”‚       â”œâ”€â”€ collect_wikipedia_articles()    â”œâ”€â”€ train()          â”‚
â”‚       â”œâ”€â”€ clean_text()                    â”œâ”€â”€ encode()          â”‚
â”‚       â””â”€â”€ save_texts()                    â””â”€â”€ tokenize_file()   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Classes Core (src/)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  DataCollector  â”‚    â”‚    Tokenizer    â”‚    â”‚  TextDatasetâ”‚  â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚             â”‚  â”‚
â”‚  â”‚ + collect_wiki()â”‚    â”‚ + train()       â”‚    â”‚ + __getitem__â”‚  â”‚
â”‚  â”‚ + clean_text()  â”‚    â”‚ + encode()      â”‚    â”‚ + __len__() â”‚  â”‚
â”‚  â”‚ + save_texts()  â”‚    â”‚ + decode()      â”‚    â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    GPTModel                                 â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ + vocab_size: int                                           â”‚ â”‚
â”‚  â”‚ + d_model: int                                              â”‚ â”‚
â”‚  â”‚ + n_heads: int                                              â”‚ â”‚
â”‚  â”‚ + n_layers: int                                             â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚ + forward(input_ids, targets) â†’ logits, loss               â”‚ â”‚
â”‚  â”‚ + generate(input_ids, ...) â†’ generated_tokens              â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚              TransformerBlock                          â”‚ â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚
â”‚  â”‚  â”‚ + attention: MultiHeadAttention                        â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ + norm1, norm2: LayerNorm                               â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ + feed_forward: FeedForward                             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ + forward(x, mask) â†’ x                                  â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚            MultiHeadAttention                          â”‚ â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚
â”‚  â”‚  â”‚ + d_model, n_heads, d_k: int                            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ + w_q, w_k, w_v, w_o: Linear                            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ + forward(q, k, v, mask) â†’ context                      â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚               FeedForward                               â”‚ â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚
â”‚  â”‚  â”‚ + linear1, linear2: Linear                              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ + forward(x) â†’ x                                        â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚    Generation   â”‚    â”‚     Utils       â”‚                     â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚                     â”‚
â”‚  â”‚ + strategies    â”‚    â”‚ + config        â”‚                     â”‚
â”‚  â”‚ + sampling      â”‚    â”‚ + device mgmt   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Interface Utilisateur                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  app/main.py (Streamlit)                                        â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                Streamlit App                               â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ + load_model_and_tokenizer()                               â”‚ â”‚
â”‚  â”‚ + generate_text()                                          â”‚ â”‚
â”‚  â”‚ + UI Components:                                           â”‚ â”‚
â”‚  â”‚   - st.chat_input()                                        â”‚ â”‚
â”‚  â”‚   - st.sidebar sliders                                     â”‚ â”‚
â”‚  â”‚   - st.chat_message()                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Flux d'ExÃ©cution DÃ©taillÃ©

### Phase 1: Collecte de DonnÃ©es
```
User â†’ download_data.py â†’ DataCollector.collect_wikipedia_articles()
                           â†“
                    DataCollector.clean_text()
                           â†“
                    DataCollector.save_texts()
                           â†“
                    Fichier: data/raw/wikipedia_corpus.txt
```

### Phase 2: PrÃ©traitement (Tokenisation)
```
Corpus brut â†’ preprocess.py â†’ Tokenizer.train()
                              â†“
                       Tokenizer.tokenize_file()
                              â†“
                       Fichier: data/processed/tokenized_corpus.txt
```

### Phase 3: EntraÃ®nement
```
DonnÃ©es tokenisÃ©es â†’ training.py â†’ TextDataset.__getitem__()
                                   â†“
                            GPTModel.forward() + loss
                                   â†“
                            Optimizer.step()
                                   â†“
                            ModÃ¨le sauvegardÃ©: models/gpt_model.pth
```

### Phase 4: InfÃ©rence/GÃ©nÃ©ration
```
Prompt utilisateur â†’ GPTModel.generate() â†’ MultiHeadAttention.forward()
                      â†“                    â†“
               Tokenizer.encode()    FeedForward.forward()
                      â†“                    â†“
               Tokens IDs        TransformerBlock.forward()
                      â†“                    â†“
               GPTModel.forward()    Causal Masking
                      â†“                    â†“
               Logits â†’ Sampling   Tokens gÃ©nÃ©rÃ©s
                      â†“
               Tokenizer.decode()
                      â†“
               Texte final
```

## Relations Entre Classes

### HÃ©ritage
- `GPTModel` hÃ©rite de `nn.Module` (PyTorch)

### Composition
- `GPTModel` contient `TransformerBlock[]`
- `TransformerBlock` contient `MultiHeadAttention` + `FeedForward`
- `MultiHeadAttention` contient `Linear[]` layers

### Utilisation
- `DataCollector` utilise `wikipedia` API
- `Tokenizer` utilise `sentencepiece`
- `TextDataset` hÃ©rite de `torch.utils.data.Dataset`
- `Streamlit App` utilise `GPTModel` + `Tokenizer`

## Ã‰tats du Pipeline

```
Ã‰tat Initial:
â”œâ”€â”€ data/raw/ (vide)
â”œâ”€â”€ data/processed/ (vide)
â””â”€â”€ models/ (vide)

AprÃ¨s collecte:
â”œâ”€â”€ data/raw/wikipedia_corpus.txt âœ…
â”œâ”€â”€ data/processed/ (vide)
â””â”€â”€ models/tokenizer.* âœ… (entraÃ®nÃ©)

AprÃ¨s prÃ©traitement:
â”œâ”€â”€ data/raw/wikipedia_corpus.txt âœ…
â”œâ”€â”€ data/processed/tokenized_corpus.txt âœ…
â””â”€â”€ models/tokenizer.* âœ…

AprÃ¨s entraÃ®nement:
â”œâ”€â”€ data/raw/ âœ…
â”œâ”€â”€ data/processed/ âœ…
â””â”€â”€ models/gpt_model.pth âœ…

PrÃªt pour infÃ©rence:
â”œâ”€â”€ ModÃ¨le chargÃ© en mÃ©moire
â”œâ”€â”€ Tokenizer chargÃ©
â””â”€â”€ Interface Streamlit active
```

## Points d'Extension

### Pour Phase 2 (RAG):
- Ajouter `VectorDatabase` class
- Ajouter `EmbeddingModel` class
- Ã‰tendre `DataCollector` pour documents internes

### Pour Phase 3 (Web Agent):
- Ajouter `WebScraper` class
- Ajouter `SearchEngine` class
- Ã‰tendre gÃ©nÃ©ration avec tools

### Pour Phase 4 (Reasoning):
- Ajouter `ReasoningEngine` class
- Ã‰tendre `GPTModel` avec CoT prompting

---

*Ce diagramme montre comment chaque classe s'articule dans le pipeline complet, de la donnÃ©e brute Ã  l'interface utilisateur.*